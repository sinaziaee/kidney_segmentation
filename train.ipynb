{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset2d import Dataset2D\n",
    "from model import UNet\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import model_hyper_parameters as config\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from losses import DiceLoss, GeneralizedDiceLoss\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DiceScore(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super().__init__()\n",
    "        self.normalization = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, inputs, targets, smooth=1):\n",
    "        inputs = self.normalization(inputs)\n",
    "\n",
    "        targets = targets[:, 1:2, ...]\n",
    "        inputs = torch.where(inputs[:, 1:2, ...] > 0.5, 1.0, 0.0)\n",
    "\n",
    "        inputs = inputs.reshape(-1)\n",
    "        targets = targets.reshape(-1)\n",
    "\n",
    "        intersection = (inputs * targets).sum()\n",
    "        dice = (2. * intersection + smooth) / (inputs.sum() + targets.sum() + smooth)\n",
    "\n",
    "        return dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'makeDataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\src\\jupyter_codes\\kidney_segmentation\\train.ipynb Cell 3\u001b[0m line \u001b[0;36m7\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/src/jupyter_codes/kidney_segmentation/train.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m tr \u001b[39m=\u001b[39m transforms\u001b[39m.\u001b[39mCompose([\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/src/jupyter_codes/kidney_segmentation/train.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     transforms\u001b[39m.\u001b[39mRandomCrop(\u001b[39m256\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/src/jupyter_codes/kidney_segmentation/train.ipynb#W2sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m ])\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/src/jupyter_codes/kidney_segmentation/train.ipynb#W2sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39m# make dataLoader\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/src/jupyter_codes/kidney_segmentation/train.ipynb#W2sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m trainds \u001b[39m=\u001b[39m makeDataset(kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m, location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata_npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/src/jupyter_codes/kidney_segmentation/train.ipynb#W2sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m validds \u001b[39m=\u001b[39m makeDataset(kind\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m, location\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mdata_npy\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/src/jupyter_codes/kidney_segmentation/train.ipynb#W2sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m trainLoader \u001b[39m=\u001b[39m DataLoader(trainds, batch_size\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mBATCH_SIZE, shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/src/jupyter_codes/kidney_segmentation/train.ipynb#W2sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m                         pin_memory\u001b[39m=\u001b[39mconfig\u001b[39m.\u001b[39mPIN_MEMORY)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'makeDataset' is not defined"
     ]
    }
   ],
   "source": [
    "# define Transform\n",
    "tr = transforms.Compose([\n",
    "    transforms.RandomCrop(256)\n",
    "])\n",
    "\n",
    "# make dataLoader\n",
    "trainds = makeDataset(kind='train', location='data_npy')\n",
    "validds = makeDataset(kind='valid', location='data_npy')\n",
    "\n",
    "trainLoader = DataLoader(trainds, batch_size=config.BATCH_SIZE, shuffle=True,\n",
    "                        pin_memory=config.PIN_MEMORY)\n",
    "validLoader = DataLoader(validds, batch_size=config.BATCH_SIZE, shuffle=False,\n",
    "                        pin_memory=config.PIN_MEMORY)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0.0001]\n",
    "os.makedirs('final_result', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (lr_) in params:\n",
    "    # Define Model################################################################################################\n",
    "    unet = UNet(64, 5, use_xavier=True, use_batchNorm=True, dropout=0.5, retain_size=True, nbCls=2)\n",
    "\n",
    "    devices = 'cpu'\n",
    "    device_num = 0\n",
    "    if torch.cuda.is_available():\n",
    "        devices = 'gpu'\n",
    "        device_num = torch.cuda.device_count()\n",
    "        if device_num > 1:\n",
    "            unet = torch.nn.DataParallel(unet)\n",
    "    unet.to(config.DEVICE)\n",
    "    #############################################################################################################\n",
    "\n",
    "    # Define History, optimizer, schedular, loss function########################################################\n",
    "    history = {'train_loss': [], 'valid_loss': [], 'dice_valid_score': []}\n",
    "    num_train = int(len(trainds) // config.BATCH_SIZE)\n",
    "    writer = SummaryWriter(log_dir='./runs/Train')\n",
    "    opt = torch.optim.NAdam(unet.parameters(), lr=lr_)\n",
    "    schedular = ReduceLROnPlateau(opt, 'min', patience=5, factor=0.25, verbose=True)\n",
    "    dicelossfunc = GeneralizedDiceLoss(normalization='softmax')\n",
    "    diceScore = DiceScore()\n",
    "    #############################################################################################################\n",
    "\n",
    "    # main train#################################################################################################\n",
    "    pbar = tqdm(range(config.N_EPOCHS), leave=False, position=0)\n",
    "    for e in pbar:\n",
    "        unet.train()\n",
    "        totalloss = 0\n",
    "        totalvalidloss = 0\n",
    "        totalvaliddice = 0\n",
    "\n",
    "        trainstep = 0\n",
    "        validstep = 0\n",
    "\n",
    "        inner_pbar = tqdm(range(num_train), leave=False, position=1)\n",
    "        data_iter = iter(trainLoader)\n",
    "        for i in inner_pbar:\n",
    "            (x, y) = next(data_iter)\n",
    "            (x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\n",
    "            pred = unet(x)\n",
    "            loss = dicelossfunc(pred, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            totalloss += loss\n",
    "            trainstep += 1\n",
    "            inner_pbar.set_postfix({'Train_loss': \"{:.4f}\".format(loss)})\n",
    "\n",
    "        with torch.no_grad():\n",
    "            unet.eval()\n",
    "            for (x, y) in validLoader:\n",
    "                (x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\n",
    "                pred = unet(x)\n",
    "                validloss = dicelossfunc(pred.clone(), y.clone())\n",
    "                totalvalidloss += validloss\n",
    "\n",
    "                validScore = diceScore(pred, y)\n",
    "\n",
    "                totalvaliddice += validScore\n",
    "                validstep += 1\n",
    "\n",
    "        avgloss = (totalloss / trainstep).cpu().detach().numpy()\n",
    "        avgvalidloss = (totalvalidloss / validstep).cpu().detach().numpy()\n",
    "        avgvaliddice = (totalvaliddice / validstep).cpu().detach().numpy()\n",
    "\n",
    "        schedular.step(avgvalidloss)\n",
    "\n",
    "        history['train_loss'].append(avgloss)\n",
    "        history['valid_loss'].append(avgvalidloss)\n",
    "        history['dice_valid_score'].append(avgvaliddice)\n",
    "\n",
    "        writer.add_scalar('train_loss', avgloss, e)\n",
    "        writer.add_scalar('validation_loss', avgvalidloss, e)\n",
    "        writer.add_scalar('validation_dice', avgvaliddice, e)\n",
    "\n",
    "        writer.add_scalars('loss', {'Train': avgloss, 'Valid': avgvalidloss}, e)\n",
    "\n",
    "        pbar.set_postfix({'Train_avg_loss': '{:.4f}'.format(avgloss),\n",
    "                        'Valid_avg_loss': '{:.4f}'.format(avgvalidloss),\n",
    "                        'Valid_avg_dice': '{:.4f}%'.format(100 * avgvaliddice)})\n",
    "\n",
    "        torch.save(unet.state_dict(), './final_result/unet_{}.pt'.format(e + 1))\n",
    "        with open('./final_result/history_{}.pkl'.format(e + 1), 'wb') as f:\n",
    "            pickle.dump(history, f)\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    print('Saving model...\\n\\n')\n",
    "    torch.save(unet.state_dict(), './final_result/UNet.pt')\n",
    "\n",
    "    print('Saving figure...\\n\\n')\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(history['train_loss'], label='Train_Dice_Loss')\n",
    "    plt.plot(history['valid_loss'], label='Validation_Dice_Loss')\n",
    "    plt.title('Training Dice Score on Dataset')\n",
    "    plt.xlabel('Number of Epoch')\n",
    "    plt.ylabel('Dice Loss')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.savefig('./final_result/train_result.png')\n",
    "\n",
    "    print('Saving History...\\n\\n')\n",
    "    with open('./final_result/history.pkl', 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "\n",
    "print('***************End of System***************')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
