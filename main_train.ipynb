{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.makedataset import makeDataset\n",
    "from models.unet import UNet\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "import utils.config as config\n",
    "import torch.nn as nn\n",
    "import pickle\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from utils.Losses import DiceLoss, GeneralizedDiceLoss\n",
    "from torchvision import transforms\n",
    "from models.eff_unet import EffUNet\n",
    "import torch.nn.functional as F\n",
    "from models.mcdropout import MCDropout2D\n",
    "# from segresnet import SegResNet\n",
    "import monai\n",
    "from monai.networks.nets.segresnet import SegResNet\n",
    "from utils.my_dice_score import DiceScore\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# define Transform\n",
    "tr = transforms.Compose([\n",
    "    # transforms.RandomCrop(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomVerticalFlip(),\n",
    "    transforms.RandomRotation(90),\n",
    "    # transforms.RandomResizedCrop(512, scale=(0.8, 1.0), ratio=(1.0, 1.0)),\n",
    "    # transforms.ColorJitter(brightness=(0.75, 1.25)),\n",
    "])\n",
    "\n",
    "dataset_folder_path = 'data_npy2'\n",
    "\n",
    "# make dataLoader\n",
    "# trainds = makeDataset(kind='train', location=dataset_folder_path, transform=tr)\n",
    "# validds = makeDataset(kind='valid', location=dataset_folder_path)\n",
    "\n",
    "\n",
    "trainds_augmented = makeDataset(kind='train', location=dataset_folder_path, transform=tr)\n",
    "trainds_original = makeDataset(kind='train', location=dataset_folder_path)\n",
    "trainds = torch.utils.data.ConcatDataset([trainds_augmented, trainds_original])\n",
    "\n",
    "validds = makeDataset(kind='valid', location=dataset_folder_path)\n",
    "BATCH_SIZE = 60                                                         \n",
    "trainLoader = DataLoader(trainds, batch_size=BATCH_SIZE, shuffle=True,\n",
    "                        pin_memory=config.PIN_MEMORY)\n",
    "validLoader = DataLoader(validds, batch_size=BATCH_SIZE, shuffle=False,\n",
    "                        pin_memory=config.PIN_MEMORY)\n",
    "\n",
    "print(config.DEVICE)\n",
    "output_folder = 'final_result16'\n",
    "params = [0.001]\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "for (lr_) in params:\n",
    "    # Define Model################################################################################################\n",
    "    # model = UNet(64, 5, use_xavier=True, use_batchNorm=True, dropout=0.5, retain_size=True, nbCls=2)\n",
    "    # model = EffUNet(1, 5, use_xavier=True, use_batchNorm=True, dropout=0.5, retain_size=True, nbCls=2)\n",
    "    model = EffUNet(1, 5, use_xavier=True, use_batchNorm=True, dropout=0.2, retain_size=True, nbCls=2)\n",
    "    \n",
    "    # model = SegResNet(\n",
    "    # spatial_dims=2,\n",
    "    # init_filters=16,\n",
    "    # in_channels=1,\n",
    "    # out_channels=2,\n",
    "    # dropout_prob=0.2,\n",
    "    # )\n",
    "    \n",
    "\n",
    "    # model = SegResNet(in_channels=1, num_classes=2, dropout_rate=0.2)\n",
    "\n",
    "    devices = 'cpu'\n",
    "    device_num = 0\n",
    "    if torch.cuda.is_available():\n",
    "        devices = 'gpu'\n",
    "        device_num = torch.cuda.device_count()\n",
    "        if device_num > 1:\n",
    "            model = torch.nn.DataParallel(model)\n",
    "    model.to(config.DEVICE)\n",
    "    #############################################################################################################\n",
    "\n",
    "    # Define History, optimizer, schedular, loss function########################################################\n",
    "    history = {'train_loss': [], 'valid_loss': [], 'dice_valid_score': []}\n",
    "    num_train = int(len(trainds) // BATCH_SIZE)\n",
    "    writer = SummaryWriter(log_dir='./runs/Train')\n",
    "    opt = torch.optim.NAdam(model.parameters(), lr=lr_)\n",
    "    schedular = ReduceLROnPlateau(opt, 'min', patience=5, factor=0.25, verbose=True)\n",
    "    # dicelossfunc = GeneralizedDiceLoss(normalization='softmax')\n",
    "    dicelossfunc = GeneralizedDiceLoss(normalization='softmax')\n",
    "    # class_weights = [1.0, 1.5]  # Example: Non-kidney (background) is penalized more\n",
    "    # dicelossfunc = GeneralizedDiceLoss(normalization='softmax', class_weights=class_weights)\n",
    "\n",
    "    diceScore = DiceScore()\n",
    "    #############################################################################################################\n",
    "    NO_EPOCH = 40\n",
    "    # main train#################################################################################################\n",
    "    pbar = tqdm(range(NO_EPOCH), leave=False, position=0)\n",
    "    max_avgvaliddice = 0\n",
    "    for e in pbar:\n",
    "        model.train()\n",
    "        totalloss = 0\n",
    "        totalvalidloss = 0\n",
    "        totalvaliddice = 0\n",
    "\n",
    "        trainstep = 0\n",
    "        validstep = 0\n",
    "\n",
    "        inner_pbar = tqdm(range(num_train), leave=False, position=1)\n",
    "        data_iter = iter(trainLoader)\n",
    "        for i in inner_pbar:\n",
    "            (x, y) = next(data_iter)\n",
    "            (x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\n",
    "            pred = model(x)\n",
    "            loss = dicelossfunc(pred, y)\n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "            totalloss += loss\n",
    "            trainstep += 1\n",
    "            inner_pbar.set_postfix({'Train_loss': \"{:.4f}\".format(loss)})\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for (x, y) in validLoader:\n",
    "                (x, y) = (x.to(config.DEVICE), y.to(config.DEVICE))\n",
    "\n",
    "                pred = model(x)\n",
    "                validloss = dicelossfunc(pred.clone(), y.clone())\n",
    "                totalvalidloss += validloss\n",
    "\n",
    "                validScore = diceScore(pred, y)\n",
    "\n",
    "                totalvaliddice += validScore\n",
    "                validstep += 1\n",
    "\n",
    "        avgloss = (totalloss / trainstep).cpu().detach().numpy()\n",
    "        avgvalidloss = (totalvalidloss / validstep).cpu().detach().numpy()\n",
    "        avgvaliddice = (totalvaliddice / validstep).cpu().detach().numpy()\n",
    "        \n",
    "\n",
    "        schedular.step(avgvalidloss)\n",
    "\n",
    "        history['train_loss'].append(avgloss)\n",
    "        history['valid_loss'].append(avgvalidloss)\n",
    "        history['dice_valid_score'].append(avgvaliddice)\n",
    "\n",
    "        writer.add_scalar('train_loss', avgloss, e)\n",
    "        writer.add_scalar('validation_loss', avgvalidloss, e)\n",
    "        writer.add_scalar('validation_dice', avgvaliddice, e)\n",
    "\n",
    "        writer.add_scalars('loss', {'Train': avgloss, 'Valid': avgvalidloss}, e)\n",
    "\n",
    "        pbar.set_postfix({'Train_avg_loss': '{:.4f}'.format(avgloss),\n",
    "                        'Valid_avg_loss': '{:.4f}'.format(avgvalidloss),\n",
    "                          'Valid_avg_dice': '{:.4f}%'.format(100 * avgvaliddice)})\n",
    "\n",
    "        torch.save(model.state_dict(), './{}/unet_{}.pt'.format(output_folder, e + 1))\n",
    "        with open('./{}/history_{}.pkl'.format(output_folder, e + 1), 'wb') as f:\n",
    "            pickle.dump(history, f)\n",
    "            \n",
    "        if avgvaliddice > max_avgvaliddice:\n",
    "            max_avgvaliddice = avgvaliddice\n",
    "            torch.save(model.state_dict(), f'./{output_folder}/UNet.pt')\n",
    "\n",
    "    writer.flush()\n",
    "    writer.close()\n",
    "\n",
    "    print('Saving model...\\n\\n')\n",
    "    torch.save(model.state_dict(), f'./{output_folder}/UNet.pt')\n",
    "\n",
    "    print('Saving figure...\\n\\n')\n",
    "    plt.style.use('ggplot')\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    plt.plot(history['train_loss'], label='Train_Dice_Loss')\n",
    "    plt.plot(history['valid_loss'], label='Validation_Dice_Loss')\n",
    "    plt.title('Training Dice Score on Dataset')\n",
    "    plt.xlabel('Number of Epoch')\n",
    "    plt.ylabel('Dice Loss')\n",
    "    plt.legend(loc='lower left')\n",
    "    plt.savefig(f'./{output_folder}/train_result.png')\n",
    "\n",
    "    print('Saving History...\\n\\n')\n",
    "    with open(f'./{output_folder}/history.pkl', 'wb') as f:\n",
    "        pickle.dump(history, f)\n",
    "\n",
    "print('***************End of System***************')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
