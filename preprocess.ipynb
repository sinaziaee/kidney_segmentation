{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import utils as utils\n",
    "from scipy.ndimage import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_path(path=None):\n",
    "    if path:\n",
    "        return path\n",
    "    else:\n",
    "        return os.getcwd()\n",
    "\n",
    "# new_folder = 'data_npy'\n",
    "# new_folder = 'data_npy2'\n",
    "new_folder = 'kits23'\n",
    "\n",
    "if not os.path.exists(f'{get_current_path()}/{new_folder}'):\n",
    "    os.mkdir(f'{get_current_path()}/{new_folder}')\n",
    "    \n",
    "if not os.path.exists(f'{get_current_path()}/{new_folder}/train'):\n",
    "    os.mkdir(f'{get_current_path()}/{new_folder}/train')\n",
    "    \n",
    "if not os.path.exists(f'{get_current_path()}/{new_folder}/valid'):\n",
    "    os.mkdir(f'{get_current_path()}/{new_folder}/valid')\n",
    "    \n",
    "if not os.path.exists(f'{get_current_path()}/{new_folder}/test'):\n",
    "    os.mkdir(f'{get_current_path()}/{new_folder}/test')\n",
    "    \n",
    "def make_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "\n",
    "train_image_path = make_path(f'{get_current_path()}/{new_folder}/train/image')\n",
    "train_segment_path = make_path(f'{get_current_path()}/{new_folder}/train/segmentation')\n",
    "valid_image_path = make_path(f'{get_current_path()}/{new_folder}/valid/image')\n",
    "valid_segment_path = make_path(f'{get_current_path()}/{new_folder}/valid/segmentation')\n",
    "test_image_path = make_path(f'{get_current_path()}/{new_folder}/test/image')\n",
    "test_segment_path = make_path(f'{get_current_path()}/{new_folder}/test/segmentation')\n",
    "\n",
    "# src_train_image_path = '/scratch/student/sinaziaee/datasets/3d_dataset/training/images'\n",
    "# src_valid_image_path = '/scratch/student/sinaziaee/datasets/3d_dataset/validation/images'\n",
    "# src_test_image_path = '/scratch/student/sinaziaee/datasets/3d_dataset/testing/images' \n",
    "\n",
    "# src_train_mask_path = '/scratch/student/sinaziaee/datasets/3d_dataset/training/labels'\n",
    "# src_valid_mask_path = '/scratch/student/sinaziaee/datasets/3d_dataset/validation/labels'\n",
    "# src_test_mask_path = '/scratch/student/sinaziaee/datasets/3d_dataset/testing/labels' \n",
    "\n",
    "src_folder_name = '3d_zero_padded_images'\n",
    "\n",
    "src_train_image_path = f'{src_folder_name}/training/images'\n",
    "src_valid_image_path = f'{src_folder_name}/validation/images'\n",
    "src_test_image_path = f'{src_folder_name}/testing/images' \n",
    "\n",
    "src_train_mask_path = f'{src_folder_name}/training/labels'\n",
    "src_valid_mask_path = f'{src_folder_name}/validation/labels'\n",
    "src_test_mask_path = f'{src_folder_name}/testing/labels'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [14:23<00:00, 14.63s/it]\n",
      "100%|██████████| 10/10 [02:26<00:00, 14.66s/it]\n",
      "100%|██████████| 8/8 [01:56<00:00, 14.55s/it]\n"
     ]
    }
   ],
   "source": [
    "def perform_image_slicing(root_path, saving_path):\n",
    "    count = 0\n",
    "    depth_list = []\n",
    "    for file_name in tqdm(sorted(os.listdir(root_path))):\n",
    "        # print(os.path.join(root_path, file_name))\n",
    "        if file_name.endswith('.nii.gz'):\n",
    "            img_id = str(file_name.split('_')[1])\n",
    "            img = nib.load(os.path.join(root_path, file_name)).get_fdata()\n",
    "            # normalizing the image between 0 and 1\n",
    "            img=(img-img.min())/(max((img.max()-img.min()),1e-3))\n",
    "            depth = img.shape[2]\n",
    "            depth_list.append(depth)\n",
    "            for j in range(depth):\n",
    "                new_path=os.path.join(saving_path, '{:05d}.npy'.format(j+count))\n",
    "                new_img = torch.tensor(img[:, :, j:j+1].astype(np.float32))\n",
    "                new_img = new_img.permute(2, 0, 1)\n",
    "                new_img = np.array(new_img)\n",
    "                new_img = np.squeeze(new_img, axis=0)\n",
    "                new_img = rotate(new_img, 90)\n",
    "                new_img = np.expand_dims(new_img, axis=0)\n",
    "                np.save(new_path, new_img)\n",
    "            count += depth\n",
    "    return depth_list\n",
    "\n",
    "train_depth_list = perform_image_slicing(root_path=src_train_image_path, saving_path=train_image_path)\n",
    "valid_depth_list = perform_image_slicing(root_path=src_valid_image_path, saving_path=valid_image_path)\n",
    "test_depth_list = perform_image_slicing(root_path=src_test_image_path, saving_path=test_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "depth_lists = {\n",
    "    'train': train_depth_list,\n",
    "    'valid': valid_depth_list,\n",
    "    'test': test_depth_list\n",
    "}\n",
    "\n",
    "json_file_path = f'{new_folder}/depth_lists.json'\n",
    "\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(depth_lists, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512, 512]\n",
      "512 512\n",
      "512 512\n",
      "512 512\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "json_file_path = f'{new_folder}/depth_lists.json'\n",
    "\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "print(data['train'])\n",
    "print(min(data['train']), max(data['train']))\n",
    "print(min(data['valid']), max(data['valid']))\n",
    "print(min(data['test']), max(data['test']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [21:14<00:00, 21.60s/it]\n",
      "100%|██████████| 10/10 [03:33<00:00, 21.33s/it]\n",
      "100%|██████████| 8/8 [02:53<00:00, 21.73s/it]\n"
     ]
    }
   ],
   "source": [
    "def perform_segment_slicing(root_path, saving_path):\n",
    "    count = 0\n",
    "    depth_list = []\n",
    "    for file_name in tqdm(sorted(os.listdir(root_path))):\n",
    "        # print(os.path.join(root_path, file_name))\n",
    "        seg_id = str(file_name.split('_')[1]).split('.')[0]\n",
    "        seg = nib.load(os.path.join(root_path, file_name)).get_fdata()\n",
    "        seg_no_cancer=np.where(seg>0,1,0).astype(np.uint8)\n",
    "        depth = seg_no_cancer.shape[2]\n",
    "        depth_list.append(depth)\n",
    "        for j in range(depth):\n",
    "            new_path=os.path.join(saving_path, '{:05d}.npy'.format(j+count))\n",
    "            seg_1ch=torch.tensor(seg_no_cancer[:, :,j:j+1],dtype=torch.int64)\n",
    "            seg_1ch = np.array(seg_1ch)\n",
    "            seg_1ch = np.squeeze(seg_1ch, axis=2)\n",
    "            seg_1ch = rotate(seg_1ch, 90)\n",
    "            seg_1ch = np.expand_dims(seg_1ch, axis=2)\n",
    "            seg_1ch = torch.tensor(seg_1ch)\n",
    "            seg_2ch=F.one_hot(seg_1ch,num_classes=2)\n",
    "            seg_2ch=torch.squeeze(seg_2ch.permute(3,0,1,2))\n",
    "            seg_2ch=np.array(seg_2ch,dtype=np.uint8)\n",
    "            np.save(new_path,seg_2ch)\n",
    "        count += depth\n",
    "\n",
    "perform_segment_slicing(root_path=src_train_mask_path, saving_path=train_segment_path)\n",
    "perform_segment_slicing(root_path=src_valid_mask_path, saving_path=valid_segment_path)\n",
    "perform_segment_slicing(root_path=src_test_mask_path, saving_path=test_segment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_slices(imaging_path, segmentation_path):\n",
    "    imaging_slice = np.load(imaging_path)\n",
    "    segmentation_slice = np.load(segmentation_path)\n",
    "\n",
    "    # Squeeze the singleton dimension if it exists\n",
    "    imaging_slice = np.transpose(imaging_slice, (1, 2, 0))\n",
    "    imaging_slice = np.squeeze(imaging_slice)\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.imshow(imaging_slice, cmap='gray')\n",
    "    ax.imshow(segmentation_slice[1], cmap='Reds', alpha=0.3)\n",
    "    ax.set_title('Imaging Slice with Segmentation')\n",
    "    ax.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    plt.imshow(imaging_slice, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
