{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/student/sinaziaee/mini_conda/miniconda3/envs/test/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import nibabel as nib\n",
    "import os\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import time\n",
    "from tqdm.auto import tqdm\n",
    "import utils as utils\n",
    "from scipy.ndimage import rotate\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['1: 82.05', '2: 78.95', '3: 82.53', '4: 83.47', '5: 83.92', '6: 85.60', '7: 88.58', '8: 90.68', '9: 80.46', '10: 88.54', '11: 90.04', '12: 88.22', '13: 81.30', '14: 92.12', '15: 90.62', '16: 86.84', '17: 83.56', '18: 91.45', '19: 91.88', '20: 89.18', '21: 90.96', '22: 92.71', '23: 89.57', '24: 93.36', '25: 92.09', '26: 94.13', '27: 95.42', '28: 91.54', '29: 94.03', '30: 89.44', '31: 90.32', '32: 93.18', '33: 93.93', '34: 95.31', '35: 95.16', '36: 93.51', '37: 89.65', '38: 93.28', '39: 91.36', '40: 90.90']\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Open the .pkl file\n",
    "with open('final_result14/history_40.pkl', 'rb') as f:\n",
    "    # Load the object from the file\n",
    "    obj = pickle.load(f)\n",
    "\n",
    "# Print the text inside the object\n",
    "print([f'{i+1}: {100*value:.2f}' for i, value in enumerate(obj['dice_valid_score'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_current_path(path=None):\n",
    "    if path:\n",
    "        return path\n",
    "    else:\n",
    "        return os.getcwd()\n",
    "\n",
    "new_folder = 'data_npy4'\n",
    "\n",
    "if not os.path.exists(f'{get_current_path()}/{new_folder}'):\n",
    "    os.mkdir(f'{get_current_path()}/{new_folder}')\n",
    "    \n",
    "if not os.path.exists(f'{get_current_path()}/{new_folder}/train'):\n",
    "    os.mkdir(f'{get_current_path()}/{new_folder}/train')\n",
    "    \n",
    "if not os.path.exists(f'{get_current_path()}/{new_folder}/valid'):\n",
    "    os.mkdir(f'{get_current_path()}/{new_folder}/valid')\n",
    "    \n",
    "if not os.path.exists(f'{get_current_path()}/{new_folder}/test'):\n",
    "    os.mkdir(f'{get_current_path()}/{new_folder}/test')\n",
    "    \n",
    "def make_path(path):\n",
    "    if not os.path.exists(path):\n",
    "        os.makedirs(path)\n",
    "    return path\n",
    "\n",
    "train_image_path = make_path(f'{get_current_path()}/{new_folder}/train/image')\n",
    "train_segment_path = make_path(f'{get_current_path()}/{new_folder}/train/segmentation')\n",
    "valid_image_path = make_path(f'{get_current_path()}/{new_folder}/valid/image')\n",
    "valid_segment_path = make_path(f'{get_current_path()}/{new_folder}/valid/segmentation')\n",
    "test_image_path = make_path(f'{get_current_path()}/{new_folder}/test/image')\n",
    "test_segment_path = make_path(f'{get_current_path()}/{new_folder}/test/segmentation')  \n",
    "\n",
    "src_folder_name = '3d_zero_padded_images'\n",
    "\n",
    "src_train_image_path = f'{src_folder_name}/training/images'\n",
    "src_valid_image_path = f'{src_folder_name}/validation/images'\n",
    "src_test_image_path = f'{src_folder_name}/testing/images' \n",
    "\n",
    "src_train_mask_path = f'{src_folder_name}/training/labels'\n",
    "src_valid_mask_path = f'{src_folder_name}/validation/labels'\n",
    "src_test_mask_path = f'{src_folder_name}/testing/labels'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [12:35<00:00, 12.81s/it]\n",
      "100%|██████████| 10/10 [02:09<00:00, 12.92s/it]\n",
      "100%|██████████| 8/8 [01:42<00:00, 12.85s/it]\n"
     ]
    }
   ],
   "source": [
    "def perform_image_slicing(root_path, saving_path):\n",
    "    count = 0\n",
    "    depth_list = []\n",
    "    for file_name in tqdm(sorted(os.listdir(root_path))):\n",
    "        # print(os.path.join(root_path, file_name))\n",
    "        if file_name.endswith('.nii.gz'):\n",
    "            img_id = str(file_name.split('_')[1])\n",
    "            img = nib.load(os.path.join(root_path, file_name)).get_fdata()\n",
    "            # normalizing the image between 0 and 1\n",
    "            img=(img-img.min())/(max((img.max()-img.min()),1e-3))\n",
    "            depth = img.shape[1]\n",
    "            depth_list.append(depth)\n",
    "            for j in range(depth):\n",
    "                # j = 255\n",
    "                new_path=os.path.join(saving_path, '{:05d}.npy'.format(j+count))\n",
    "                new_img = torch.tensor(img[:, j:j+1, :].astype(np.float32))\n",
    "                # new_img = new_img.permute(2, 0, 1)\n",
    "                new_img = np.array(new_img)\n",
    "                # print(new_img.shape)\n",
    "                new_img = np.squeeze(new_img, axis=1)\n",
    "                # print(new_img.shape)\n",
    "                new_img = rotate(new_img, 90)\n",
    "                new_img = np.expand_dims(new_img, axis=0)\n",
    "            #     plt.imshow(new_img[0], cmap='gray')\n",
    "            #     plt.axis('off')\n",
    "            #     plt.show()\n",
    "            #     break\n",
    "            # break\n",
    "                np.save(new_path, new_img)\n",
    "            count += depth\n",
    "    return depth_list\n",
    "train_depth_list = perform_image_slicing(root_path=src_train_image_path, saving_path=train_image_path)\n",
    "valid_depth_list = perform_image_slicing(root_path=src_valid_image_path, saving_path=valid_image_path)\n",
    "test_depth_list = perform_image_slicing(root_path=src_test_image_path, saving_path=test_image_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "depth_lists = {\n",
    "    'train': train_depth_list,\n",
    "    'valid': valid_depth_list,\n",
    "    'test': test_depth_list\n",
    "}\n",
    "\n",
    "json_file_path = f'{new_folder}/depth_lists.json'\n",
    "\n",
    "with open(json_file_path, 'w') as json_file:\n",
    "    json.dump(depth_lists, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 59/59 [15:30<00:00, 15.77s/it]\n",
      "100%|██████████| 10/10 [02:38<00:00, 15.87s/it]\n",
      "100%|██████████| 8/8 [02:05<00:00, 15.70s/it]\n"
     ]
    }
   ],
   "source": [
    "def perform_segment_slicing(root_path, saving_path):\n",
    "    count = 0\n",
    "    depth_list = []\n",
    "    for file_name in tqdm(sorted(os.listdir(root_path))):\n",
    "        # print(os.path.join(root_path, file_name))\n",
    "        seg_id = str(file_name.split('_')[1]).split('.')[0]\n",
    "        seg = nib.load(os.path.join(root_path, file_name)).get_fdata()\n",
    "        seg_no_cancer=np.where(seg>0,1,0).astype(np.uint8)\n",
    "        depth = seg_no_cancer.shape[1]\n",
    "        depth_list.append(depth)\n",
    "        for j in range(depth):\n",
    "            # j=150\n",
    "            new_path=os.path.join(saving_path, '{:05d}.npy'.format(j+count))\n",
    "            seg_1ch=torch.tensor(seg_no_cancer[:, j:j+1, :],dtype=torch.int64)\n",
    "            seg_1ch = np.array(seg_1ch)\n",
    "            seg_1ch = np.squeeze(seg_1ch, axis=1)\n",
    "            seg_1ch = rotate(seg_1ch, 90)\n",
    "            seg_1ch = np.expand_dims(seg_1ch, axis=2)\n",
    "            seg_1ch = torch.tensor(seg_1ch)\n",
    "            # print(seg_1ch.shape)\n",
    "            seg_2ch=F.one_hot(seg_1ch,num_classes=2)\n",
    "            # print(seg_2ch.shape)            \n",
    "            seg_2ch=torch.squeeze(seg_2ch.permute(3,0,1,2))\n",
    "            seg_2ch=np.array(seg_2ch,dtype=np.uint8)\n",
    "            # print(seg_2ch.shape)\n",
    "            # plt.imshow(seg_2ch[1,:,:], cmap='gray')\n",
    "            # plt.show()\n",
    "            np.save(new_path,seg_2ch)\n",
    "        #     break\n",
    "        # break\n",
    "        count += depth\n",
    "\n",
    "perform_segment_slicing(root_path=src_train_mask_path, saving_path=train_segment_path)\n",
    "perform_segment_slicing(root_path=src_valid_mask_path, saving_path=valid_segment_path)\n",
    "perform_segment_slicing(root_path=src_test_mask_path, saving_path=test_segment_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
