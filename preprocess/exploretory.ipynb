{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"final_dataset/train/image\", exist_ok=True)\n",
    "os.makedirs(\"final_dataset/train/segmentation\", exist_ok=True)\n",
    "os.makedirs(\"final_dataset/valid/image\", exist_ok=True)\n",
    "os.makedirs(\"final_dataset/valid/segmentation\", exist_ok=True)\n",
    "os.makedirs(\"final_dataset/test/image\", exist_ok=True)\n",
    "os.makedirs(\"final_dataset/test/segmentation\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "json_file_path = 'data_npy/depth_lists.json'\n",
    "\n",
    "depth_dict = {}\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    depth_dict = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_non_kidneys(root_path, depth_dict, kind):\n",
    "    file_path_list = []\n",
    "    for file_path in sorted(os.listdir(root_path)):\n",
    "        file_path_list.append(os.path.join(root_path, file_path))\n",
    "\n",
    "    count_slices = 0\n",
    "    removing_list = set()\n",
    "    for depth in depth_dict[kind]:\n",
    "        count_no_kidney_slices = 0\n",
    "        for i in range(depth):\n",
    "            inx = count_slices + i\n",
    "            file_path = file_path_list[inx]\n",
    "            arr = np.load(file_path)[1]\n",
    "            \n",
    "            if np.max(arr) == 0:\n",
    "                count_no_kidney_slices += 1\n",
    "        #########################################\n",
    "        no_not_checking = count_no_kidney_slices // 2        \n",
    "        flag_counter = 0\n",
    "        for i in range(depth):\n",
    "            inx = count_slices + i\n",
    "            file_path = file_path_list[inx]\n",
    "            arr = np.load(file_path)[1]\n",
    "            \n",
    "            if flag_counter > no_not_checking:\n",
    "                break\n",
    "            else:\n",
    "                if np.max(arr) == 0:\n",
    "                    flag_counter += 1\n",
    "                    removing_list.add(file_path.split('/')[-1])\n",
    "            \n",
    "            if np.max(arr) == 0:\n",
    "                count_no_kidney_slices += 1\n",
    "        count_slices += depth\n",
    "    return removing_list\n",
    "\n",
    "import shutil\n",
    "\n",
    "def create_new_dataset(root_path, destination_folder, removing_list):\n",
    "    count = 0\n",
    "    for file_path in sorted(os.listdir(root_path)):\n",
    "        if file_path not in removing_list:\n",
    "            count += 1\n",
    "            source_folder = os.path.join(root_path, file_path)\n",
    "            shutil.copy(source_folder, destination_folder)\n",
    "    print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "removing_list_train = find_non_kidneys(root_path='data_npy/train/segmentation', depth_dict=depth_dict, kind='train')\n",
    "removing_list_valid = find_non_kidneys(root_path='data_npy/valid/segmentation', depth_dict=depth_dict, kind='valid')\n",
    "removing_list_test = find_non_kidneys(root_path='data_npy/test/segmentation', depth_dict=depth_dict, kind='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10389\n",
      "1964\n",
      "1344\n",
      "10389\n",
      "1964\n",
      "1344\n"
     ]
    }
   ],
   "source": [
    "create_new_dataset(root_path='data_npy/train/image/', destination_folder='final_dataset/train/image/', removing_list=removing_list_train)\n",
    "create_new_dataset(root_path='data_npy/valid/image/', destination_folder='final_dataset/valid/image/', removing_list=removing_list_valid)\n",
    "create_new_dataset(root_path='data_npy/test/image/', destination_folder='final_dataset/test/image/', removing_list=removing_list_test)\n",
    "\n",
    "create_new_dataset(root_path='data_npy/train/segmentation/', destination_folder='final_dataset/train/segmentation/', removing_list=removing_list_train)\n",
    "create_new_dataset(root_path='data_npy/valid/segmentation/', destination_folder='final_dataset/valid/segmentation/', removing_list=removing_list_valid)\n",
    "create_new_dataset(root_path='data_npy/test/segmentation/', destination_folder='final_dataset/test/segmentation/', removing_list=removing_list_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_train = len(os.listdir('final_dataset/train/image/'))\n",
    "len_valid = len(os.listdir('final_dataset/train/image/'))\n",
    "len_test = len(os.listdir('final_dataset/train/image/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def renamer(kind):\n",
    "    for i, file_path in enumerate(sorted(os.listdir(f'final_dataset/{kind}/image/'))):\n",
    "        num =  '{:05d}'.format(i)\n",
    "        os.rename(os.path.join(f'final_dataset/{kind}/image/', file_path), os.path.join(f'final_dataset/{kind}/image/', num+'.npy')) \n",
    "        os.rename(os.path.join(f'final_dataset/{kind}/segmentation/', file_path), os.path.join(f'final_dataset/{kind}/segmentation/', num+'.npy'))\n",
    "renamer('train')\n",
    "renamer('valid')\n",
    "renamer('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37250\n"
     ]
    }
   ],
   "source": [
    "print(len(os.listdir('kits19/train/image')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SegResNet(\n",
      "  (act_mod): ReLU(inplace=True)\n",
      "  (convInit): Convolution(\n",
      "    (conv): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "  )\n",
      "  (down_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Identity()\n",
      "      (1): ResBlock(\n",
      "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Convolution(\n",
      "        (conv): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResBlock(\n",
      "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ResBlock(\n",
      "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Convolution(\n",
      "        (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResBlock(\n",
      "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ResBlock(\n",
      "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): Sequential(\n",
      "      (0): Convolution(\n",
      "        (conv): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): ResBlock(\n",
      "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (2): ResBlock(\n",
      "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (3): ResBlock(\n",
      "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "      (4): ResBlock(\n",
      "        (norm1): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 128, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_layers): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): ResBlock(\n",
      "        (norm1): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 64, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): ResBlock(\n",
      "        (norm1): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 32, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): ResBlock(\n",
      "        (norm1): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        (norm2): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "        (act): ReLU(inplace=True)\n",
      "        (conv1): Convolution(\n",
      "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "        (conv2): Convolution(\n",
      "          (conv): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (up_samples): ModuleList(\n",
      "    (0): Sequential(\n",
      "      (0): Convolution(\n",
      "        (conv): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): UpSample(\n",
      "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0), mode='bilinear')\n",
      "      )\n",
      "    )\n",
      "    (1): Sequential(\n",
      "      (0): Convolution(\n",
      "        (conv): Conv2d(64, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): UpSample(\n",
      "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0), mode='bilinear')\n",
      "      )\n",
      "    )\n",
      "    (2): Sequential(\n",
      "      (0): Convolution(\n",
      "        (conv): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      )\n",
      "      (1): UpSample(\n",
      "        (upsample_non_trainable): Upsample(scale_factor=(2.0, 2.0), mode='bilinear')\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (conv_final): Sequential(\n",
      "    (0): GroupNorm(8, 16, eps=1e-05, affine=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Convolution(\n",
      "      (conv): Conv2d(16, 2, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (dropout): Dropout2d(p=0.2, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import monai\n",
    "from monai.networks.nets.segresnet import SegResNet\n",
    "\n",
    "SegResNet_model = SegResNet(\n",
    "    spatial_dims=2,\n",
    "    init_filters=16,\n",
    "    in_channels=1,\n",
    "    out_channels=2,\n",
    "    dropout_prob=0.2,\n",
    ")\n",
    "print(SegResNet_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
